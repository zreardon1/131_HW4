---
title: "131_HW4"
author: "Zack Reardon"
date: "11/3/2022"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache.extra = rand_seed)
```

```{r, message=FALSE}
library(tidyverse)
library(ISLR)
library(ISLR2)
library(tidymodels)
library(MASS)
library(parsnip)
library(discrim)
tidymodels_prefer()

titanic <- read_csv("/Users/zackreardon/Downloads/homework-3/data/titanic.csv")

# converting to factors
titanic$survived <- as.factor(titanic$survived)
titanic$pclass <- as.factor(titanic$pclass)
```

Question 1.

```{r}
set.seed(100)

titanic_split <- initial_split(titanic, prop = 0.70, strata = survived)

titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)

# verifying correct number of observations
dim(titanic_train) 
dim(titanic_test)
```

Question 2.

```{r}
titanic_folds <- vfold_cv(titanic_train, v=10)
titanic_folds
```

Question 3.

In Question 2 we are cross-validating the titanic training data by subdividing it into 10 groups. K-fold cross validation refers to subdividing the data into k groups for the use in cross-validation. The model in question is fitted to 9 of the 10 groups (or k-1 of the k) groups and the MSE of the left out group is calculated. This is repeated to calculate the MSEs of each of the 10 (or k) available groups to be left out. By applying the learned model to the left out groups, an estimate of the test MSE can be obtained. This is useful since it can help in determining which models has a better estimation of the MSE. If we were to use the whole training set, the resampling method would be validation set.

Question 4.

```{r}
# implement same recipe as HW3
titanic_recipe <- recipe(survived ~ pclass + sex + age + sib_sp + parch + fare, data = titanic_train) %>%
  step_impute_linear(age, impute_with = imp_vars(all_predictors())) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(~ starts_with("sex"):fare) %>%
  step_interact(~ age:fare)
```

```{r}
# set up logistic regression workflow
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

log_wkflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(titanic_recipe)

# set up linear discriminant analysis workflow
lda_mod <- discrim_linear() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")

lda_wkflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(titanic_recipe)

# set up quadratic discriminant analysis workflow
qda_mod <- discrim_quad() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")

qda_wkflow <- workflow() %>% 
  add_model(qda_mod) %>% 
  add_recipe(titanic_recipe)
```
30 models will be fitted in total.

Question 5.

```{r, eval=FALSE}
# fit logistic regression model
log_fit <- fit_resamples(log_wkflow, titanic_folds)

# fit linear discriminant analysis workflow
lda_fit <- fit_resamples(lda_wkflow, titanic_folds)

# fit quadratic discriminant analysis workflow
qda_fit <- fit_resamples(qda_wkflow, titanic_folds)

save(log_fit, file="log_results.rda")
save(lda_fit, file="lda_results.rda")
save(qda_fit, file="qda_results.rda")
```

Question 6.

```{r}
load("log_results.rda")
load("lda_results.rda")
load("qda_results.rda")

# find mean and standard errors of the performance accuracy
collect_metrics(log_fit)
collect_metrics(lda_fit)
collect_metrics(qda_fit)
```